\documentclass{report}

\usepackage{natbib}
\usepackage{graphics}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{hanging}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{placeins}

% \VignetteIndexEntry{Introduction to the AFLP package}
% \VignetteDepends{methods, lme4, reshape, plyr, ggplot2, vegan, xtable, mvtnorm}
% \VignetteKeyword{AFLP}
% \VignetteKeyword{genetics}

\newcommand{\R}{{\normalfont\textsf{R }}{}}
\newcommand{\NA}{{\normalfont\textsf{NA }}{}}

\DeclareGraphicsExtensions{.png,.pdf,.jpg}

\begin{document}

\SweaveOpts{png = TRUE}
\SweaveOpts{resolution = 100}
\SweaveOpts{keep.source = TRUE}

<<foo,include=FALSE,echo=FALSE>>=
library(AFLP)
options(width = 60)
options(str = strOptions(strict.width = "cut"))
foo <- packageDescription("AFLP")
@

\title{Introduction to the '\texttt{AFLP}' package\\(version \Sexpr{foo$Version})}

\author{Thierry Onkelinx}
\maketitle
\chapter{Terminology}
\begin{description}
  \item[specimen] the sample as recieved in the lab. Each sample requires a unique code. It will be divided into one or more replicates. Specimens with multiple replicates will be used to asses the repeatability.
  \item[group] the a priori clustering of specimens e.g. per location, per species, \ldots
  \item[replicate] a subsample of a specimen. The DNA extraction, PCR reaction and fluorescence measurement are done at this level. Thus replicates are unique.
  \item[plate] a batch of replicates with simultaneous PCR reaction. Each cell in a plate is referenced by a lane and a capilar
  \item[capilar] label of the capilar. The number of capilars depend on the lab equiment. E.g. an ABI 3500 uses 8 capilars, a LiCor slabgel is regarded as one capilar.
  \item[lane] on a LiCor slabgel: the position of the replicates. On a capilar system: the number of the run within the plate.
  \item[fluorescence]
  \item[marker]
  \item[normalisation]
  \item[classification]
  \item[repeatability]
\end{description}

\chapter{Reading in data}

\section{The design}
First we must define the design: the position of each replicate on the plates, the link between replicate and specimen. The \textit{Group} column is optional and only relevant if some a priori clustering is assumed. The grouping in the Tilia dataset is the field determination of the species (see \S\ref{S:Tilia}). All columns, exect \textit{Group}, present in the TiliaDesign \texttt{data.frame} are mandatory. Extra columns will be appended to the AFLP object, but ignored during analysis.

When the data.frame is proper formatted, you can transform it into an \texttt{AFLP} object using the \textbf{as.AFLP} function. All mandatory columns will be converted to factors.

<<reading data>>=
data(TiliaDesign)
str(TiliaDesign)
summary(TiliaDesign)
Tilia <- as.AFLP(TiliaDesign)
@

\section{The fluorescence data}

In the example the AFLP analysis was run on a LiCor slabgel and the fluorescence was measured using SAGA software. It is easy to add the text file output from SAGA to an \texttt{AFLP} object using the \textbf{readSAGA} function. Be carefull with the names of the replicates. The names in SAGA file and the \texttt{AFLP} object must be indentical. Keep in mind that the replicate names are read as header by \textbf{readSAGA} and thus all rules for the names of \texttt{data.frame} apply. We recommend to start names of replicates with a letter and to use only letters, numbers and points. Please note that \R is case-sensitive. The \textit{textclean} argument can be used to pass a user-defined function to do some cleaning on the replicate names.

<<adding fluorescence data from SAGA>>=
Tilia <- readSAGA(
  system.file("extdata", "Tilia_bandvaluespc1", package = "AFLP"), 
  add.to = Tilia)
str(fluorescence(Tilia))
summary(fluorescence(Tilia))
@

The fluorescence can be added manually as well. In this case you need to prepare a \texttt{data.frame} with 6 columns: \textit{PC} (a factor indicating the primer combination), \textit{Replicate} (a factor with the replicate ID), \textit{Fluorescence} (the measured fluorescence), \textit{Marker} (the size of the marker in basepairs), \textit{Normalised} (\NA, will hold the normalised fluorescence) and \textit{Score} (\NA, will hold the classification).

<<eval = FALSE>>=
fluorescence(Tilia) <- Your.data.frame
@


\chapter{Normalising the raw fluorescence}
\section{\textbf{clean} and \textbf{normalise}}
\label{S:normalise}
Prior to the normalisation you should use the \textbf{clean} function. This will do some sanity checking on the \texttt{AFLP} object, especially on missing data.

<<clean run>>=
Tilia <- clean(Tilia)
output <- normalise(Tilia, output = "none")
@

The normalisation estimates the effects of replicate, plate, lane, capilar and marker on the average fluorescence. The algorithm selects the appropriate combination of effects based on the design and the number of markers. The user has to decide which transformation to use. One can choose among \texttt{transformation = "log"} (default), \texttt{transformation = "logit"} and \texttt{transformation = "none"}.

The user has three options for \textit{output}: \texttt{"screen"} (default), \texttt{"tex"} and \texttt{"none"}. \texttt{"screen"} does the normalisation and displays the model that is used in the normalisation and some standard graphs and tables to asses potential problems with the data. \texttt{"tex"} is equal to \texttt{"screen"} except that the output generates \LaTeX code for include the graphs and table in a document. It generates a section for each primer combination and a subsection for each random effect. \texttt{"none"} does the normalisation without generating tables and graphs. Therefore it is the fastest option.

The graphs consist of QQ plots for the best unbiased lineair predictions (BLUPs) of the random effects and QQ plots of the residuals. As simple linear model is fitted for each QQ plot, quantifying the linear relationship between the observed and the theoretical values. The predictions of this model and their $100 \times level\%$ prediction intervals and added to the QQ plots. \textit{level} is an argument of \textbf{normalise} and defaults to \texttt{0.99}. Observed values outside these prediction interval are marked as "possible outliers" and tabulated. See \S\ref{S:detectingOutliers} for more information on outlier detection.

<<normalise display, eval = FALSE>>=
output <- normalise(Tilia, output = "tex", device = "png")
@

<<normalise run, echo = FALSE, results = tex>>=
output <- normalise(Tilia, output = "tex", device = "png")
@

\section{Detecting and removing outliers}
The result of \textbf{normalise} is a \texttt{list} with two objects: \textit{data} contains an \texttt{AFLP} object and \textit{outliers} contains an \texttt{AFLP.outlier} object. The \texttt{AFLP} object in the output of \textbf{normalise} is the one passed to the \textit{data} argument with updated the \texttt{model} and \texttt{Normalised} values. All other information remains unchanged. The \texttt{AFLP.outlier} object contains all tabulated outliers (see \S\ref{S:normalise}). Note than although the option \texttt{output = "none"} will no display outliers, it will add them to the \texttt{AFLP.outlier} object. However we recommend to use the graphs for outlier inspection.

Before taking decissions on removing outliers, we need to know how to interpet the QQ-plots. We take the replicates as an example. An observed value of $0$ indicates that signal of that replicate is as strong as the signal of an average replicate. Positive observed values thus indicate stronger signals and negative values weaker signals. A values of $-0.5$ with the \texttt{"log"} transformation can be interpreted as the strength of the signal of this replicate is $\exp(-0.5) = 0.607$ times the strength of an average replicate. Very weak signals can be due to failed amplification. Very strong signals can be due to contamination. We can give a similar interpretation to the effects of plate, capilar, marker and residual. Strong effects for plate or capilar indicate that possibly something when wrong in the lab. Strong marker effects indicate differences in amplification among markers. Outlying residuals are indications of problems with measuring the fluorescence.

Ideally all points on the QQ-plot form a more or less continuous pattern, which does not need to be a straight line. Isolated points at both ends of the QQ-plot are the most important points to look for. If they are present (e.g. the three lowest points and maybe the highest point in the QQ-plot for the replicates), we recommend to have a look at the lab data to see if there is a problem. Keep the point if the lab data has no indications for problems, otherwise remove it.

We recommend to check the outliers in a stepwise fashion. First start with the worst possible lab problems: entire plates which are problematic. Then check for smaller lab problems: problems at the level of individual replicates. Then we look at the level of the markers. And finaly at the residuals. When outliers are removing for a given step, then one should run \textbf{normalise} again and restart the checking at the level of the plates.

In primer combination 1 of the \texttt{Tilia} dataset we find no outliers at the plates levels. The inspection of the replicate level highlights 3 low effects and 1 high effect. We descid to remove only the 3 low replicate after inspection of the slab gels.

<<remove outliers from replicates>>=
#extra the outliers for the replicates from the 
#AFLP.outlier object in the output
repOutliers <- replicates(output$outliers)
#select the 3 lowest effects for PC1
toRemove <- head(subset(repOutliers, PC == "PC1"), 3)
toRemove
#no outliers in the Tilia dataset
replicates(outliers(Tilia))
Tilia <- addOutliers(Tilia, toRemove)
#the outliers are added
replicates(outliers(Tilia))
@

Now we have to rerun the normalisation.

<<normalise display 2, eval = FALSE>>=
output <- normalise(Tilia, output = "tex", device = "png")
@

<<normalise run 2, echo = FALSE, results = tex>>=
output <- normalise(Tilia, output = "tex", device = "png")
@

\chapter{Classifying the (normalised) fluorescence}

The normalisation removes the effects of plate, replicate, capilar, marker,\ldots for the fluorescence. We expect that the normalise fluoresence of polymorphic markers has a bimodal distribution: a baseline fluorescence when the marker is absent and a high fluorescence when the marker is present. On top of that there will be some measurement error changing the fluorescence. So we don't get two values but a range of values.

\textbf{classify} estimates the density distribution of the normalised fluorescence for each marker. These distributions are displayed on graphs when the user sets \textit{output} to \texttt{"screen"} (default) or \texttt{"tex"}. Then the algorithm looks for different peaks in the distribution. A peak is a local maximum with a height which is at least \textit{thresholdPeakRatio} of the largest peak (default = \texttt{0.03}). The border between two peaks is set at the local minimum between two sufficiently large local maxima. If this results in more than \textit{maxBorder} border(s) (default = \texttt{1}), then only the \textit{maxBorder} smallest border(s) are retained. Then there is only one sufficiently large local maximum, then the border is set at \texttt{Inf}. Such markers are considered monomorphic. The normalised fluorescence is binned with these borders and the result is stored in the \texttt{Score} variable in the \texttt{fluorescence} \texttt{data.frame} of the \texttt{AFLP} object.

<<classify display, eval = FALSE>>=
Tilia <- output$data
Tilia <- classify(Tilia, output = "tex", device = "png")
@

<<classify run, echo = FALSE, results = tex>>=
Tilia <- output$data
Tilia <- classify(Tilia, output = "tex", device = "png")
@


\chapter{Estimating repeatability}

Any classification has a risk for misclassification. However, this risk is high variable. In order to work with thrustworthy data, we strongly recommend to assest the repeatability of the analysis. A second analysis of the same sample should, in theory, yield an identical DNA fingerprint. This is in practice hardly the case since the signal can be influenced by other factors than just the true underlying signal from the DNA.

\section{Repeatability based on the fluorescence}
A first way to investigate this, it to look at the variance in raw fluorescence within measurements for the same marker and the same specimen. The variance is zero when all measurements are equal and increases when the differences become larger. We calculate these variances for each combination of marker and specimen that have multiple measurement (e.g. specimens with more than one replicate per specimen). Averaging these variances over a given specimen gives an idea of the average repeatability of that specimen. A low score indicates very similar measurements within the specimen, whereas a high score is an indication of dissimilar measurements. E.g. when one of the replicates of a specimen has a problematic amplification, the fluorescence measurements will be much lower than the other replicates of that specimen. That would result in a high average variance. Likewise we can aggregate over a given marker, highlighting potential problems due to the marker and not the replicates. The interpretation is similar.

Normalising the fluorescence should remove some of the noise in the data due to batch effects. Therefore the repeatability score for the normalised fluorescence will on average be lower than the repeatability score of the raw fluorescence. The \textbf{repeatability} function create two scatterplots displaying the repeatability score for the raw versus the normalised fluorescence score (provided \texttt{output = "screen"} or \texttt{output = "tex"}). The line indicates equal repeatability scores. Thus most of the points should be on the lower righthand side of this line (indicating more variability in the raw fluorescence than in the normalised fluorescence).

\section{Repeatability based on scores}

When the (normalised) fluorescence is classified into presence-absence data, then we expect that all replicates of a given specimen get the same state for a given marker. E.g. the marker is either present or absent in all replicates. If not, then we clearly have misclassifications. Unfortunalty, we don't know the truth: is the marker is reality present or absent in a given specimen? We assume that the majority is correctly classified. Assume we have five replicates of a given specimen and for a given marker we get 4 absences and 1 presence. The majority is absent, thus we assume 1 misclassification. Due to our assumption, the maximum number of misclassifications is not equal to the number of replicates but the half that number rounded down to an integer. Thus we have maximum 2 misclassifications when we have 5 replicates (see table~\ref{tab:Misclassifcation}). Based on the observed scores on a given marker for all replicate of a given specimen and our assumption, we can calculate the observed number of errors and the maximum number of errors.

\begin{table}[hbt]
  \begin{center}
  \begin{tabular}{rrlr}
  \hline
  Absent & Present & Assumption & Misclassifications \\
  \hline
  0 & 5 & Present & 0 \\
  1 & 4 & Present & 1 \\
  2 & 3 & Present & 2 \\
  3 & 2 & Absent & 2 \\
  4 & 1 & Absent & 1 \\
  5 & 0 & Absent & 0 \\
  \hline
  \end{tabular}
  \label{tab:Misclassifcation}
  \caption{Number of absent and present scores of a given marker for the replicates of a given specimen and the resulting assumption and number of misclassifications.}
  \end{center}
\end{table}

When we aggregate these numbers we get meaningfull information on markers or specimens. Our repeatability scores are based on the sums of the observed errors and the sum of the theoretically maximum number of errors. \eqref{eq:ScoreMarker} defines the repeatability $R_i$ for a marker $i$ and \eqref{eq:ScoreSpecimen} the reapeatability $R_j$ for specimen $j$ . $t_{ij}$ is the theoretical maximum number of errors for marker $i$ and specimen $j$, $o_{ij}$ is the observed maximum number of errors for marker $i$ and specimen $j$, $s$ is the number of specimens and $m$ the number of markers. $R_i$ and $R_j$ are restricted to the interval $[0, 1]$, with 1 indicating no observed errors (perfect repeatability) and 0 indicating that the number of observed errors is always equal to the theoretical maximum (not repeatable at all).

\begin{equation}
  \label{eq:ScoreMarker}
  R_i = \dfrac{\sum\limits_{j = 1} ^s t_{ij} - \sum\limits_{j = 1} ^s o_{ij}}{\sum\limits_{j = 1} ^s t_{ij}}
\end{equation}

\begin{equation}
  \label{eq:ScoreSpecimen}
  R_j = \dfrac{\sum\limits_{i = 1} ^m t_{ij} - \sum\limits_{j = 1} ^m o_{ij}}{\sum\limits_{j = 1} ^m t_{ij}}
\end{equation}

<<repeat display, eval = FALSE>>=
output <- repeatability(Tilia, output = "tex", device = "png")
@

<<repeat run , echo = FALSE, results = tex>>=
output <- repeatability(Tilia, output = "tex", device = "png")
@


\section{Generating a design with replication}

\chapter{Further analysis}

\appendix

\chapter{Tilia dataset}
\label{S:Tilia}
The Tilia dataset is a collection of leaf samples from 489 specimens of lime trees collected in Belgium. Field specialists determined the species of each tree and classified the specimens as belonging to \textit{Tilia cordata}, \textit{Tilia platyphylos} or their hybrid \textit{Tilia europea (x)}. Some specimens were not classified in the field (table~\ref{tab:TiliaN}). The research goal was to see whether the field determination matches with the genetical information.

<<results = tex, echo = FALSE>>=
data(TiliaDesign)
library(xtable)
SpecList <- unique(TiliaDesign[, c("Group", "Specimen")])
SpecList <- aggregate(
  SpecList[, "Specimen", drop = FALSE], 
  by = SpecList[, "Group", drop = FALSE], 
  FUN = length)
print(xtable(SpecList, caption = "Number of specimen per group."), include.rownames = FALSE, label = "tab:TiliaN")
@

The AFLP was run on a LiCor Sequencer system with primer combination from table\ref{tab:Primers}. 

\begin{table}
  \begin{centering}
  \begin{tabular}{llr}
  \hline
  Code & Primer combination & Label \\
  \hline
  PC1 & E-ACT M-CTG & 700 \\
  PC2 & E-ACG M-CAA & 800 \\
  PC3 & E-AGC M-CAT & 700 \\
  PC4 & E-ACA M-CTG & PC4 \\
  \hline
  \end{tabular}
  \caption{Used primer combination and labels}
  \end{centering}
  \label{tab:Primers}
\end{table}

The LiCor images were imported in the Saga MX  software. The images were sized using a size standard \textbf{(which?)} placed on lane 1. Desmiling was done using about xxx monomorphic markers in the 50 - 400 bp range. Then potential markers were selected. The fluoresence and size of of all selected bands were measured by the software and exported as tab-delimited text files. These files are available in the \texttt{extdata} folder of the package.

The design of the experiment is available as the \textit{Tiliadesign} \texttt{data.frame}.

We would like to thank Kristien Vander Mijnsbrugge and An Vanden Broeck for their permission to use the dataset in the AFLP package.

\end{document}
